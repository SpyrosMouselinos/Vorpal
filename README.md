# Vorpal - Production Video Classification System

High-accuracy video classification using semantic embeddings for hierarchical categorization of video captions.

## Overview

**Architecture:** BAAI/bge-large-en-v1.5 embeddings + SVM classifier

**Performance:**
- **Coarse Model** (45 categories): 60.35% accuracy
- **Fine Model** (422 subcategories): ~40-45% accuracy (estimated)
- **Inference Speed:** ~5-6ms per video

## Installation

```bash
pip install -r requirements.txt
```

## Quick Start

### 1. Configure

Two pre-configured models:
- `configs/config_coarse.yaml` - Category-level classification (45 classes)
- `configs/config_fine.yaml` - Subcategory-level classification (422 classes)

### 2. Train

```bash
# Train category classifier
python train.py --config configs/config_coarse.yaml

# Train subcategory classifier  
python train.py --config configs/config_fine.yaml
```

**Training time:**
- First run: ~2-3 minutes (computes embeddings, caches them)
- Subsequent runs: <1 minute (uses cached embeddings)

### 3. Evaluate

```bash
python eval.py --config configs/config_coarse.yaml --checkpoint models/model_coarse.pkl
```

### 4. Inference

```bash
# Single text
echo "workers in blue uniforms operate heavy machinery" | \
  python inference.py --config configs/config_coarse.yaml \
  --checkpoint models/model_coarse.pkl --stdin --show_proba

# Batch CSV
python inference.py --config configs/config_coarse.yaml \
  --checkpoint models/model_coarse.pkl \
  --input_csv your_videos.csv --text_column description \
  --show_proba > predictions.tsv
```

## Project Structure

```
Vorpal/
├── Core Scripts
│   ├── train.py              # Training script
│   ├── eval.py               # Evaluation script
│   └── inference.py          # Inference script
│
├── Data Generation (Optional)
│   ├── generate_data_with_claude.py   # Generate with Claude Haiku 4.5
│   ├── generate_data_with_gemini.py   # Generate with Gemini 2.5 Flash
│   ├── generate_data_with_openai.py   # Generate with GPT-4o-mini
│   └── combine_datasets.py            # Merge provider datasets
│
├── Configuration
│   ├── configs/
│   │   ├── config_coarse.yaml    # 45 categories
│   │   └── config_fine.yaml      # 422 subcategories
│   ├── .env                      # API keys (your keys)
│   └── .env.example              # API key template
│
├── Models
│   ├── models/
│   │   ├── model_coarse.pkl      # Trained coarse model
│   │   ├── model_fine.pkl        # Trained fine model
│   │   ├── embedding_classifier.py
│   │   └── __init__.py
│   └── utils/
│       ├── embedding_cache.py
│       └── __init__.py
│
├── Data (19,813 train + 3,000 val)
│   └── data/
│       ├── train_combined.csv       # Combined from 3 providers
│       ├── valid_combined.csv       # Validation set
│       ├── taxonomy.json            # Category/subcategory mapping
│       └── embedding_cache/         # Cached embeddings
│
└── Documentation
    ├── README.md             # This file
    └── requirements.txt      # Dependencies
```

## Data

The system is trained on **19,813 examples** generated by 3 LLMs:
- Claude Haiku 4.5 (37.6%)
- Gemini 2.5 Flash (24.9%)
- GPT-4o-mini (37.5%)

Captions avoid category/subcategory keywords, forcing the model to learn visual patterns rather than keyword matching.

### Generating More Data (Optional)

To generate additional training data:

```bash
# Set API keys in .env file first
# Then generate from one or more providers:

python generate_data_with_claude.py   # ~$0.50-1.50
python generate_data_with_gemini.py   # ~$0.10-0.40
python generate_data_with_openai.py   # ~$0.10-0.40

# Combine all provider datasets
python combine_datasets.py

# Retrain models on expanded dataset
python train.py --config configs/config_coarse.yaml
```

Each generator creates ~7,400 training + 1,000 validation examples for all 422 subcategories.

## Taxonomy

**45 Categories** including:
- Industry & Manufacturing
- Nature & Wildlife
- Science Fiction & Futuristic
- Sports & Fitness
- Technology & Computing
- And 40 more...

**422 Subcategories** (see `data/taxonomy.json` for complete mapping)

## Model Architecture

### Embedding Model
- **BAAI/bge-large-en-v1.5**: State-of-the-art sentence embeddings
- 1024 dimensions
- ~25ms encoding time per text

### Classifier
- **LinearSVC (SVM)**: Support Vector Machine with calibration
- Probability estimates via CalibratedClassifierCV
- Balanced class weights

### Why This Architecture?

1. **Semantic Understanding**: Captures meaning, not just keywords
2. **High Accuracy**: 60.35% on 45 classes (vs 41% for bag-of-words)
3. **Fast Inference**: ~5-6ms total (25ms embedding + 1ms SVM)
4. **Production-Ready**: Proven performance on real LLM-generated data

## Configuration

Example config structure:

```yaml
model:
  type: "embedding"
  num_classes: 45
  encoder: "BAAI/bge-large-en-v1.5"
  classifier: "svm"

classifier_params:
  C: 1.0
  max_iter: 2000
  class_weight: "balanced"

embedding:
  batch_size: 32
  cache_embeddings: true  # Speeds up retraining

data:
  train_path: "data/train_combined.csv"
  valid_path: "data/valid_combined.csv"
  text_column: "caption"
  label_column: "category_id"  # or subcategory_id
```

## Performance

### Coarse Model (45 categories)
- **Accuracy**: 60.35%
- **Throughput**: ~180 videos/second (single CPU)
- **Top-5 accuracy**: ~85-90% (estimated)

### Fine Model (422 subcategories)
- **Accuracy**: ~40-45% (estimated)
- **Throughput**: ~180 videos/second
- **Top-20 accuracy**: ~75-80% (estimated)

### Performance Context
- **60.35%** on 45 classes = **27x better than random** (2.2%)
- Excellent for candidate generation in hybrid systems

## Production Usage

### Recommended Hybrid Approach

```
Video → Embedding Model → Top-3 Categories → LLM Refinement → Final Label
        (fast, 5ms)        (60% accurate)      (95%+ accurate)
```

This combines:
- ✓ Speed (fast initial filtering)
- ✓ Accuracy (LLM on reduced candidates)
- ✓ Cost-effectiveness (LLM only for ambiguous cases)

### Direct Usage

For 60% accuracy at 5ms latency, use the embedding model directly without LLM refinement.

## Advanced Usage

### Custom Taxonomy

Edit your training data to include your own categories:
1. Update `data/taxonomy.json` with your labels
2. Create training CSV with your captions
3. Update `num_classes` in config
4. Retrain

### Batch Processing

```python
import pandas as pd

# Load your data
df = pd.read_csv('videos.csv')

# Run inference
python inference.py --config configs/config_coarse.yaml \
  --checkpoint models/model_coarse.pkl \
  --input_csv videos.csv --text_column description \
  --show_proba > predictions.tsv

# Analyze results
results = pd.read_csv('predictions.tsv', sep='\t')
print(results['predicted_label'].value_counts())
```

### Fine-Tuning

To improve on your specific data:
1. Collect more training examples in your domain
2. Add to `data/train_combined.csv`
3. Re-run `python train.py --config configs/config_coarse.yaml`
4. Embeddings are cached, so retraining is fast

## Technical Details

### Embedding Cache

First training computes and caches embeddings (~2-3 min).  
Subsequent training loads from cache (<1 minute).

Cache location: `data/embedding_cache/`

To clear cache:
```python
from utils.embedding_cache import clear_cache
clear_cache()
```

### Model Size

- Coarse model: ~1.1 MB
- Fine model: ~8-10 MB
- Embedding cache: ~58 MB (one-time, reused)

### Memory Usage

- Training: ~2-3 GB RAM
- Inference: ~1 GB RAM (model loaded)

## Troubleshooting

### Out of Memory

- Reduce `batch_size` in config (e.g., 16 instead of 32)
- Process data in smaller chunks

### Slow First Training

- Normal: Computing embeddings for 20k examples takes 2-3 minutes
- Subsequent runs use cache and are <1 minute
- Inference is always fast (~5ms)

### Low Accuracy

- 60% on 45 classes without keyword matching is very good
- For higher accuracy: Add more training data or use hybrid LLM approach
- Check if your data matches the training distribution

## License

MIT

## Citation

If you use Vorpal, consider citing:
- BGE embeddings: https://github.com/FlagOpen/FlagEmbedding
- Sentence Transformers: https://www.sbert.net/
